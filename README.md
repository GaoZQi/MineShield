# æ¥å£æ–‡æ¡£

## 1.zsy

### 1.1 Dimensionality Reduction

```python
#æ•°æ®é›†è¯»å–éƒ¨åˆ†ï¼Œä¼ å…¥csvçš„æ–‡ä»¶è·¯å¾„
df = pd.read_csv(csv_path, encoding=encoding)

#å¯è§†åŒ–éƒ¨åˆ†ä»£ç ï¼Œå”¯ä¸€è¾“å‡º
    plt.figure(figsize=(8, 6))
    plt.scatter(
        result_df["PC1"],
        result_df["PC2"],
        c=result_df["cluster"],
        cmap='viridis',
        alpha=0.7,
        edgecolors='black',
        linewidths=0.5
    )
    plt.title("Title Dimensionality Reduction + Clustering Result (PCA + KMeans)")
    plt.xlabel("PC1")
    plt.ylabel("PC2")
    plt.grid(True)
    plt.show()
```

### 1.2 Linear_Regression

```python
#æ•°æ®é›†è¯»å–éƒ¨åˆ†
df = pd.read_csv(csv_path, encoding=encoding)

#è¾“å‡ºéƒ¨åˆ†ï¼Œå…ˆæ„å»ºDataFrameå’Œå‡æ–¹è¯¯å·®MSE
result_df = pd.DataFrame({
    "True Length": y_test.values,
    "Predicted Length": y_pred.round(2)
})
result_df["Error"] = (result_df["True Length"] - result_df["Predicted Length"]).abs().round(2)
#å†æ‰“å°å‡ºMSE
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error (MSE):", round(mse, 2))
#æœ€åç”Ÿæˆå¯è§†åŒ–æ•£ç‚¹å›¾
plt.scatter(range(len(y_test)), y_test, label="True", color="blue")
plt.scatter(range(len(y_pred)), y_pred, label="Predicted", color="orange")
```

### 1.3 SQLDetectModel

```python
#ä»£ç ä¸­å†™æ­»çš„è°ƒç”¨ä½ç½®
class SQLDetectModel:
    def __init__(self, model_pkl="../model/xgboost_model.pkl", le_pkl="../model/sqllabel_encoder.pkl", vectorizer_pkl="../model/vectorizer.pkl"):
#æ—¥å¿—è¯»å–é€»è¾‘
log_path = input("è¯·è¾“å…¥æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼š")
	def process_log_and_predict(log_path, model):

#æ‰€æœ‰çš„è¾“å‡ºä¿¡æ¯
user_agent = match.group(1)  # æå–User-Agent
print(f"æ­£åœ¨æ£€æµ‹çš„User-Agent: {user_agent}")  # æ‰“å°User-Agent
  result = model.predict(user_agent)
  if result == 1:
    print(f"è¯¥User-Agent ({user_agent}) ä¸ºæ¶æ„è¯·æ±‚")
  else:
    print(f"è¯¥User-Agent ({user_agent}) ä¸ºæ­£å¸¸è¯·æ±‚")
  except IndexError:
# å¦‚æœæ—¥å¿—æ ¼å¼é”™è¯¯æˆ–æ— æ³•è§£æUser-Agentï¼Œè·³è¿‡
print(f"æ— æ³•è§£æçš„æ—¥å¿—è¡Œ: {line}")
continue
```

## 2.cwc

### 2.1 ac_predict

```python
#æ¨¡å‹æ–‡ä»¶çš„è¯»å–
model_file = '../model/agglomerative_attack_detection_model.pkl'
    scaler_file = '../model/agglomerative_scaler.pkl'
    umap_file = '../model/agglomerative_umap.pkl'
    test_data_path = '../dataset/ac_train'
agglomerative_predict = AgglomerativeClusteringPredict(model_file=model_file, scaler_file=scaler_file, umap_file=umap_file, test_data_path=test_data_path)

#æ‰“å°å¯è§†åŒ–èšç±»æˆæœ
plt.scatter(self.X_test_umap[self.test_labels == label, 0], self.X_test_umap[self.test_labels == label, 1],
            color=color, label=f"{label_name}", alpha=0.7, s=40, edgecolors='black')
#å›¾è¡¨è¾“å‡º
plt.title("Agglomerative Clustering on Test Set")
plt.xlabel("UMAP Component 1")
plt.ylabel("UMAP Component 2")
plt.legend(loc='upper right', title='Cluster Labels')
plt.show()
```

### 2.2 gmm_predict

```python
#ç›¸åŒçš„è¯»å–é€»è¾‘
model_file = '../model/gmm_attack_detection_model.pkl'
    scaler_file = '../model/gmm_scaler.pkl'
    umap_file = '../model/gmm_umap.pkl'
    test_data_path = '../dataset/kddcup.data_10_percent_corrected'

    gmm_clustering = GMMClustering(model_file=model_file, scaler_file=scaler_file, umap_file=umap_file, test_data_path=test_data_path)

#pltç»˜åˆ¶å›¾å½¢è¾“å‡º
# åˆ›å»ºä¸€ä¸ªå›¾å½¢å¹¶åˆ†é…ä¸åŒçš„é¢œè‰²
plt.figure(figsize=(10, 8))

# ä¸ºæ¯ä¸ªç°‡åˆ†é…ä¸åŒçš„é¢œè‰²å’Œæ ‡è®°ï¼Œå¢åŠ é€æ˜åº¦å’Œç‚¹çš„å¤§å°
for cluster_id in np.unique(self.test_labels):
  plt.scatter(self.X_test_umap[self.test_labels == cluster_id, 0],
    self.X_test_umap[self.test_labels == cluster_id, 1],
    label=cluster_names[cluster_id], alpha=0.7, s=30, edgecolors='black', marker='o')
# æ·»åŠ æ ‡ç­¾å’Œæ ‡é¢˜
plt.title("GMM Clustering on Test Set")
plt.xlabel("UMAP Component 1")
plt.ylabel("UMAP Component 2")
plt.legend()
# æ˜¾ç¤ºå›¾å½¢
plt.show()
```

### 2.3 mlp_predict

```python
#ç…§å¸¸ä¼ å…¥æ¨¡å‹æ–‡ä»¶
mlp_model_path = '../model/mlp_model_trained.pkl'
    keras_model_path = '../model/keras_mlp_model_trained.keras'
    onehot_encoder_path = '../model/onehot_encoder.pkl'
    scaler_path = '../model/scaler.pkl'

    predictor = ModelPredictor(mlp_model_path=mlp_model_path, keras_model_path=keras_model_path, onehot_encoder_path=onehot_encoder_path, scaler_path=scaler_path)

#æµ‹è¯•é›†æ ·ä¾‹ï¼Œå†™æ­»äº†å¹¶è¾“å‡ºé¢„æµ‹ç»“æœ
sample = "51213,0.999352,tcp,http,FIN,10,10,800,1190,19.01232,62,252,5763.734863,8573.555664,2,2,111.039111,98.288445,6662.074451,165.358922,255,1472115402,1201817275,255,0.288347,0.114102,0.174245,80,119,1,149,5,1,2,2,1,5,0,0,1,2,5,0,Analysis,1"

	# è¿›è¡Œé¢„æµ‹å¹¶è¾“å‡ºç»“æœ
    result = predictor.predict(sample)
    print(result)

#å®é™…è¾“å…¥çš„æµ‹è¯•é›†è·¯å¾„
    test_data_path = '../dataset/UNSW_NB15_testing-set.csv'  # æ›¿æ¢ä¸ºæµ‹è¯•é›†è·¯å¾„
    predictor.evaluate(test_data_path)
    # è®¡ç®—å‡†ç¡®ç‡çš„å®é™…è¾“å‡ºç±»å‹
    from sklearn.metrics import accuracy_score
    accuracy_mlp = accuracy_score(y_test, y_pred_mlp)
    accuracy_keras = accuracy_score(y_test, y_pred_keras)

    print(f"MLP Classifier Accuracy: {accuracy_mlp:.4f}")
    print(f"Keras Model Accuracy: {accuracy_keras:.4f}")
```

## 3.cyq

### 3.1 K_means

```python
#è¾“å…¥æ–‡ä»¶
print(f"\nProcessing file: {file_path}")
texts = self.load_data(file_path)
    def load_data(self, file_path):
        df = pd.read_csv(file_path)
        if 'title' not in df.columns:
            raise ValueError("æ–‡ä»¶ä¸­ç¼ºå°‘ 'title' åˆ—")
        titles = df['title'].dropna().astype(str).tolist()
        if len(titles) < 5:
            raise ValueError("æ–‡æœ¬æ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦5æ¡ä»¥ä¸Šè®°å½•")
        return titles
    
#è¾“å‡ºçš„å›¾è¡¨
def show_clusters(self, reduced_data, labels):
        plt.figure(figsize=(14, 8))
        plt.scatter(
            reduced_data[:, 0], reduced_data[:, 1],
            c=labels, cmap='tab10', s=50,
            edgecolors='black', linewidths=0.5, alpha=0.7
        )
        plt.title("K-Means Clustering")
        plt.xlabel("PCA Component 1")
        plt.ylabel("PCA Component 2")
        plt.grid(True)
        plt.colorbar(label='Cluster ID')
        plt.tight_layout()
        plt.show()

def show_wordcloud(self, texts):
        all_text = " ".join(texts)
        cleaned_text = re.sub(r'\b[a-zA-Z]\b', '', all_text)
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
        wordcloud = WordCloud(
            width=1000, height=500,
            background_color='white',
            stopwords=self.stop_words_set,
            max_words=100
        ).generate(cleaned_text)

        plt.figure(figsize=(12, 6))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')
        plt.title("Word Cloud")
        plt.tight_layout()
        plt.show()
        
def print_top_keywords(self, X_dense, labels):
        for cluster_id in range(self.n_clusters):
            cluster_indices = [i for i, label in enumerate(labels) if label == cluster_id]
            if not cluster_indices:
                print(f"Cluster {cluster_id}: (empty)")
                continue
            cluster_tfidf_avg = X_dense[cluster_indices].mean(axis=0)
            print(f"Cluster {cluster_id} â†’ {top_keywords}")
```

### 3.2 One_Class_SVM_predict

```python
#å„é¢„æµ‹æ•°è¾“å‡º
        print("\né¢„æµ‹ç»“æœ:")
        print(f"é¢„æµ‹æ€»æ•°æ®é‡: {total}")
        print(f"é¢„æµ‹æ­£å¸¸æµé‡æ•°: {normal_count}")
        print(f"é¢„æµ‹å¼‚å¸¸æµé‡æ•°: {attack_count}")
        
#ç»“æœè¾“å‡ºå‡½æ•°ä¸è¾“å‡º
    def evaluate(self, y_true, y_pred):
        print("One-Class SVM Intrusion Detection Report:")
        print(classification_report(y_true, y_pred, target_names=['Attack', 'Normal']))

        cm = confusion_matrix(y_true, y_pred, labels=[1, -1])
        print("\nConfusion Matrix:")
        print(cm)
	self.evaluate(y_true, y_pred)
```

### 3.3 Random_forest_predict

```python
#é¢„æµ‹ä¸å¯è§†åŒ–è¾“å‡º
def predict_and_visualize(self, test_csv_path):
        df = self.read_csv_safely(test_csv_path)
        df['text'] = df['Title'] + ' ' + df['Description']
        X_test = self.vectorizer.transform(df['text'])
        y_pred = self.model.predict(X_test)

        # åˆ†ç±»æŠ¥å‘Š + å¯è§†åŒ–
        if 'Class Index' in df.columns:
            y_true = self.label_encoder.transform(df['Class Index'])
            class_names = [str(c) for c in self.label_encoder.classes_]
            report = classification_report(y_true, y_pred, target_names=class_names, digits=4)
            print("Classification Report:\n")
            print(report)
            self.plot_confusion_matrix(y_true, y_pred)
        else:
            print("No 'Class Index' column found. Skipping classification report and confusion matrix.")

        print("ğŸ“¡ Generating UMAP scatter plot... Please wait.")
        
#plot_umap_scatterçš„è¾“å‡º
        plt.figure(figsize=(8, 6))
        sns.scatterplot(data=df_umap, x='UMAP1', y='UMAP2', hue='Label', palette='tab10', s=30)
        plt.title("UMAP Scatter Plot (Colored by Predicted Label)")
        plt.tight_layout()
        plt.show()
        
#plot_confusion_matrixçš„è¾“å‡º
        fig, ax = plt.subplots(figsize=(8, 6))
        disp.plot(cmap="Blues", ax=ax, colorbar=True)
        plt.title("Confusion Matrix: True vs Predicted")
        plt.tight_layout()
        plt.show()
```

